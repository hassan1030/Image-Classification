{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d7310f0-7190-42ce-989c-51c6f650972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  # For progress bars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "531edd8d-f181-44eb-9342-b6122e19112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define Transformations\n",
    "# Explanation: These transformations will prepare the images for the model by resizing, normalizing, and augmenting.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),        # Resize images to 128x128 pixels\n",
    "    transforms.RandomHorizontalFlip(),    # Randomly flip images horizontally to augment data\n",
    "    transforms.ToTensor(),                # Convert images to PyTorch tensors\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize pixel values to [-1, 1]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4945206a-6ab4-4a18-869d-7f2e59ec7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load Dataset and Split into Train and Validation Sets\n",
    "\n",
    "# Explanation: Loading images from the directory and splitting the dataset into 80% training and 20% validation.\n",
    "\n",
    "dataset = datasets.ImageFolder(root='//Users/muhammadhassanzahoor/Desktop/EAI 6010 - Applications of Artificial Intelligence/Module 2/archive', transform=transform)  # Load dataset from directory\n",
    "train_size = int(0.8 * len(dataset))  # Calculate 80% of dataset size for training\n",
    "val_size = len(dataset) - train_size  # Remaining 20% for validation\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])  # Split dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bdf248f4-c99a-48c4-8176-4ee484ca22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create DataLoaders for Batch Processing\n",
    "\n",
    "# Explanation: DataLoaders help load data in batches, making training more efficient.\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # DataLoader for training data\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)  # DataLoader for validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19e3b767-47c0-4f96-8626-0be2ff23c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Load Pre-Trained Model and Modify for Binary Classification\n",
    "\n",
    "# Explanation: We use a pre-trained ResNet18 model and replace the final layer for our specific task (cats vs. dogs).\n",
    "\n",
    "model = models.resnet18(pretrained=True)  # Load pre-trained ResNet18 model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all pre-trained layers to keep their learned weights\n",
    "num_features = model.fc.in_features  # Get the number of input features to the final layer\n",
    "model.fc = nn.Linear(num_features, 2)  # Replace final layer with a binary classifier (2 classes: cat and dog)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "model = model.to(device)  # Move model to the device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34790709-c5b9-415a-83ce-58725ca6aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define Loss Function and Optimizer\n",
    "\n",
    "# Explanation: We set up the loss function and optimizer to guide how the model learns.\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification tasks\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)  # Adam optimizer, only updating the final layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abd272fc-9156-4dc5-908c-ee97f3e8b452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:09<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.2158990502357483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:09<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Training Loss: 0.2156403636932373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:09<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Training Loss: 0.21258163779973985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:09<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Training Loss: 0.19227502703666688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:10<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Training Loss: 0.17429709285497666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:09<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Training Loss: 0.18627751469612122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Training Loss: 0.18040282160043716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:10<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Training Loss: 0.1762071368098259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:10<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Training Loss: 0.15259778171777724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:10<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Training Loss: 0.17348867893218994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Training Loop\n",
    "# Explanation: The training loop goes through the data multiple times (epochs) to learn the classification task.\n",
    "epochs = 5  # Number of epochs to train the model\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0  # Track the loss for each epoch\n",
    "    \n",
    "    for images, labels in tqdm(train_loader):  # Loop over each batch\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to the device\n",
    "        \n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        outputs = model(images)  # Forward pass: get model predictions\n",
    "        loss = criterion(outputs, labels)  # Calculate the loss\n",
    "        loss.backward()  # Backward pass: compute gradients\n",
    "        optimizer.step()  # Update weights based on gradients\n",
    "        \n",
    "        running_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {running_loss/len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad973bc4-402d-4928-9f81-c6bf3b654e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1562096859727587, Accuracy: 94.0%\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Validation Loop\n",
    "# Explanation: After each epoch, we evaluate the model on the validation set to monitor for overfitting.\n",
    "model.eval()  # Set model to evaluation mode (no gradient updates)\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for validation to save memory\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to device\n",
    "        \n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Calculate validation loss\n",
    "        val_loss += loss.item()  # Accumulate validation loss\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
    "        total += labels.size(0)  # Total number of samples\n",
    "        correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "# Print validation loss and accuracy after each epoch\n",
    "print(f\"Validation Loss: {val_loss/len(val_loader)}, Accuracy: {100 * correct / total}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e9f4a-9aee-4feb-9df3-1cfde380b583",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
